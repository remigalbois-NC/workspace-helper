import { NextRequest, NextResponse } from "next/server";
import { getGoogleHelpResponse } from "../../../Chatbot-template/Chatbot/tools/google-center.js";
import { GoogleGenAI, type Content, type FunctionDeclaration, type FunctionCall, type GenerateContentResponse, Type, FunctionCallingConfigMode } from "@google/genai";

const COACH_SYSTEM_PROMPT = `
Tu es l'Expert Coach de Numericoach. Ton r√¥le est d'accompagner l'utilisateur pour qu'il devienne un ma√Ætre de Google Workspace. Tu n'es pas juste un support technique, tu es un mentor strat√©gique.

1. POSTURE & TON

Utilise exclusivement le "Tu".

Ton ton est expert, dynamique, bienveillant et l√©g√®rement complice.

Discr√©tion absolue : Ne mentionne jamais tes outils de recherche, de navigation ou le site support.google.com. L'utilisateur doit avoir l'impression que toute cette science vient de ton expertise inn√©e.

2. M√âTHODOLOGIE DE R√âPONSE

Ne te contente pas de r√©pondre √† la question pos√©e. Analyse l'intention derri√®re la demande.

Le Pivot "Best Practice" : Avant ou pendant tes explications, interpelle l'utilisateur pour challenger ses habitudes. Utilise des formules comme : "Tu sais que c'est encore plus efficace de faire comme √ßa ?" ou "Sais-tu que tu peux aussi automatiser cette partie ? Voici la meilleure pratique...".

3. STRUCTURE OBLIGATOIRE

La Solution : R√©ponse directe, claire et structur√©e √† la probl√©matique.

La M√©thode Pro : Explique pourquoi cette m√©thode est sup√©rieure aux autres (gain de temps, collaboration, s√©curit√©).

Le Conseil de ton Coach : Termine syst√©matiquement par un bloc de citation Markdown format√© exactement comme ceci :

üí° Le conseil de ton coach : [Ici, ton astuce de pro, un raccourci clavier m√©connu ou une fonctionnalit√© cach√©e qui change la donne].
`;

// Fonction de scraping d'article avec limitation de taille
export const openGoogleTopic = async (topicLink: string) => {
    try {
        console.log("üìñ [SCRAPER] Ouverture de l'article:", topicLink);
        const urlGoogleCenter = 'https://support.google.com/';
        const reqGoogle = await fetch(`${urlGoogleCenter}${topicLink}`, {
            method: "GET",
            headers: { "User-Agent": "Mozilla/5.0" }
        });
        const response = await reqGoogle.text();
        const regex = /<section\b[^>]*class\s*=\s*["'][^"']*\barticle-container\b[^"']*["'][^>]*>[\s\S]*?<\/section>/gi;
        const match = regex.exec(response);

        if (!match) return "Contenu inaccessible.";

        const cleanedContent = match[0].replace(/<[^>]*>?/gm, '').replace(/\s+/g, ' ').trim();
        return cleanedContent.substring(0, 3000);
    } catch (e) {
        console.error("‚ùå [SCRAPER ERROR]:", e);
        return "Erreur de lecture.";
    }
};

const TOOLS: { functionDeclarations: FunctionDeclaration[] }[] = [
    {
        functionDeclarations: [
            {
                name: "searchGoogleHelp",
                description: "Recherche sur le support Google.",
                parameters: {
                    type: Type.OBJECT,
                    required: ["query"],
                    properties: { query: { type: Type.STRING } },
                },
            },
            {
                name: "openGoogleTopic",
                description: "Ouvre un article sp√©cifique du support Google.",
                parameters: {
                    type: Type.OBJECT,
                    required: ["topicLink"],
                    properties: { topicLink: { type: Type.STRING } },
                },
            },
        ],
    },
];

const DEFAULT_CONFIG = {
    systemInstruction: COACH_SYSTEM_PROMPT,
    tools: TOOLS,
    toolConfig: {
        functionCallingConfig: {
            mode: FunctionCallingConfigMode.AUTO,
        },
    },
    temperature: 0.7,
    maxOutputTokens: 2048,
} as const;

/** G√©n√®re du contenu en streaming avec historique + systemInstruction. G√®re les appels d'outils de fa√ßon r√©cursive. */
async function* streamGenerate(
    ai: InstanceType<typeof GoogleGenAI>,
    contents: Content[],
    config: typeof DEFAULT_CONFIG
): AsyncGenerator<string> {
    try {
        console.log("üì§ [GEMINI] generateContentStream avec historique + systemInstruction...");

        const stream = await ai.models.generateContentStream({
            model: "gemini-2.5-flash",
            contents,
            config: {
                systemInstruction: config.systemInstruction,
                tools: config.tools,
                toolConfig: config.toolConfig,
                temperature: config.temperature,
                maxOutputTokens: config.maxOutputTokens,
            },
        });

        /** R√©cup√®re tous les appels de fonction du chunk (getter + parts brutes pour le streaming). */
        const getFunctionCallsFromChunk = (chunk: GenerateContentResponse): FunctionCall[] => {
            const fromGetter = chunk.functionCalls ?? [];
            if (fromGetter.length > 0) return fromGetter;
            const parts = chunk.candidates?.[0]?.content?.parts ?? [];
            return parts
                .filter((p): p is typeof p & { functionCall: FunctionCall } => !!p.functionCall)
                .map((p) => p.functionCall);
        };

        /** V√©rifie que les args sont complets pour ex√©cuter l'outil (√©vite les appels partiels en streaming). */
        const isCompleteFunctionCall = (name: string, args: Record<string, unknown>) => {
            if (name === "searchGoogleHelp") return "query" in args && args.query != null && String(args.query).trim() !== "";
            if (name === "openGoogleTopic") return "topicLink" in args && args.topicLink != null && String(args.topicLink).trim() !== "";
            return false;
        };

        for await (const chunk of stream) {
            if (chunk.text) {
                yield chunk.text;
            }

            const functionCalls = getFunctionCallsFromChunk(chunk);
            for (const fc of functionCalls) {
                const name = fc.name ?? "";
                const args = (fc.args ?? {}) as Record<string, unknown>;
                if (!isCompleteFunctionCall(name, args)) continue;

                console.log(`üõ†Ô∏è [TOOL CALL]: ${name}`, args);

                let toolResult: string;
                if (name === "searchGoogleHelp") {
                    toolResult = await getGoogleHelpResponse(String(args.query ?? ""));
                } else if (name === "openGoogleTopic") {
                    toolResult = await openGoogleTopic(String(args.topicLink ?? ""));
                } else {
                    toolResult = "Outil inconnu.";
                }

                console.log(`‚úÖ [TOOL RESULT]: Donn√©es r√©cup√©r√©es`);

                const modelTurn: Content = {
                    role: "model",
                    parts: [{ functionCall: { name, args } }],
                };
                const userTurn: Content = {
                    role: "user",
                    parts: [{ functionResponse: { name, response: { content: toolResult || "Aucun r√©sultat trouv√©." } } }],
                };

                yield* streamGenerate(ai, [...contents, modelTurn, userTurn], config);
            }
        }
    } catch (error: unknown) {
        console.error("‚ùå [STREAM ERROR]:", error);
        throw error;
    }
}

function buildContents(history: { role: string; content: string }[], message: string): Content[] {
    const mapped = (history ?? []).map((m) => ({
        role: m.role === "user" ? "user" : "model",
        parts: [{ text: m.content }],
    })) as Content[];
    return [...mapped, { role: "user", parts: [{ text: message }] }];
}

export async function POST(req: NextRequest) {
    try {
        const { message, history } = await req.json();

        if (!process.env.GEMINI_API_KEY) {
            return NextResponse.json({ error: "Cl√© API manquante" }, { status: 500 });
        }

        const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY });
        const contents = buildContents(Array.isArray(history) ? history : [], message);

        const encoder = new TextEncoder();

        /** Envoie un √©v√©nement SSE (format doc: flux d‚Äôinstances GenerateContentResponse). */
        const sendSSE = (controller: ReadableStreamDefaultController<Uint8Array>, event: string, data: unknown) => {
            const payload = `event: ${event}\ndata: ${JSON.stringify(data)}\n\n`;
            controller.enqueue(encoder.encode(payload));
        };

        const stream = new ReadableStream({
            async start(controller) {
                try {
                    const gen = streamGenerate(ai, contents, DEFAULT_CONFIG);
                    for await (const text of gen) {
                        if (text) sendSSE(controller, "chunk", { text });
                    }
                    sendSSE(controller, "done", {});
                    controller.close();
                } catch (error) {
                    console.error("‚ùå [STREAM ERROR]:", error);
                    const message = error instanceof Error ? error.message : "Erreur de g√©n√©ration";
                    try {
                        sendSSE(controller, "error", { message });
                    } catch {
                        // controller peut √™tre d√©j√† ferm√©
                    }
                    controller.error(error);
                }
            },
        });

        return new Response(stream, {
            headers: {
                "Content-Type": "text/event-stream",
                "Cache-Control": "no-cache",
                Connection: "keep-alive",
                "X-Accel-Buffering": "no",
            },
        });
    } catch (error: unknown) {
        console.error("üí• [POST ERROR]:", error);
        const message = error instanceof Error ? error.message : "Erreur serveur";
        return NextResponse.json({ error: message }, { status: 500 });
    }
}
